<!DOCTYPE html>
<html>

<head>
    <title>Speech Sample</title>
    <meta charset="utf-8" />
</head>

<body style="font-family:'Helvetica Neue',Helvetica,Arial,sans-serif; font-size:13px;">
    <table width="100%">
        <tr>
            <td></td>
            <td>
                <h1 style="font-weight:500;">Speech Recognition</h1>
                <h2 style="font-weight:500;">Microsoft Cognitive Services</h2>
                <h3 style="font-weight:300;">Efectividad promedio 80%</h3>
            </td>
        </tr>
        <tr>
            <td align="right"><a href="https://www.microsoft.com/cognitive-services/en-us/sign-up" target="_blank">Subscription</a>:</td>
            <td><input id="key" type="text" size="40" value="1e594011d0714aadb8735b3d57a49d4e"></td>
        </tr>
        <tr>
            <td align="right">Laguage:</td>
            <td align="left">
                <select id="languageOptions">
                    <option value="zh-CN">Chinese - CN</option>
                    <option value="en-GB">English - GB</option>
                    <option value="en-US">English - US</option>
                    <option value="fr-FR">French - FR</option>
                    <option value="de-DE">German - DE</option>
                    <option value="it-IT">Italian - IT</option>
                    <option value="es-ES"selected="selected">Spanish - ES</option>
                </select>
            </td>
        </tr>
        <tr>
            <td align="right">Recognition Mode:</td>
            <td align="left">
                <select id="recognitionMode">
                    <option value="Interactive">Interactive</option>
                    <option value="Conversation" selected="selected">Conversation</option>
                    <option value="Dictation">Dictation</option>
                </select>
            </td>
        </tr>
        <tr>
            <td align="right">Format:</td>
            <td align="left">
                <select id="formatOptions">
                    <option value="Simple">Simple Result</option>
                    <option value="Detailed" selected="selected">Detailed Result</option>
                </select>
            </td>
        </tr>
        <tr>
            <td align="right">Input:</td>
            <td align="left">
                <select id="inputSource">
                    <option value="Mic">Microphone</option>
                    <option value="File" selected="selected">Audio File</option>
                </select>
            </td>
        </tr>
        <tr>
            <td></td>
            <td>
                <button id="startBtn" disabled="disabled">Start</button>
                <button id="stopBtn" disabled="disabled">Stop</button>
                <input type="file" id="filePicker" accept=".wav" style="display:none" />
            </td>
        </tr>
        <tr>
            <td></td>
            <td>
                <table>
                    <tr>
                        <td>Results:</td>
                        <td>Current hypothesis:</td>
                    </tr>
                    <tr>
                        <td>
                            <textarea id="phraseDiv" style="display: inline-block;width:500px;height:200px"></textarea>
                        </td>
                        <td style="vertical-align: top">
                            <span id="hypothesisDiv" style="width:200px;height:200px;display:block;"></span>
                        </td>
                    </tr>
                </table>
            </td>
        </tr>
        <tr>
            <td align="right">Status:</td>
            <td align="left"><span id="statusDiv"></span></td>
        </tr>
    </table>

    <div style="max-width: 80%; font-weight:300; text-align: center;">
        <h3>Conversación</h3>
        <span id="cleanedSpeechDiv"></span>
    </div>

    <!-- The SDK has a dependency on requirejs (http://requirejs.org/). -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.3/require.min.js"></script>

    <!-- SDK REFERENCE -->
    <script src="../../distrib/speech.browser.sdk.js"></script>

    <!-- FileSaver -->
    <script src="../functions/FileSaver.js"></script>

    <!-- SDK USAGE -->
    <script>

        //Agent key words
        const agentKeyWords = [
            //Greetings
             "grabadas", "monitoreadas", "de acuerdo",
            
            //Summarize
            "el señor identificado", "la señora identificado", "el señor de nombre", "la señora de nombre",
            "cedula de ciudadania", "con direccion", "cuya direccion", 

            //Getting data
            "ofrecemos", "ofrecer", "toma de datos", "Oportunidad", "llamada", "ofrecerle", "como esta",
            "confirmar", "el motivo de esta llamada", "proceder", "podria", "me puede comentar", "me puede decir",
            "adquirir", "tiene alguna duda", "tiene alguna inquietud", "comprende", "que duda tiene", "con el", "con la", 
            "lo llamo de", "la llamo de", "podria informarme", "podria decirme", "podria confirmarme", "telefono", "direccion", 
            "cedula", "tu direccion de correspondencia", "su direccion", "residencia", "correo electronico", "entonces en le confirmó",
            "entonces en le confirmó", "me repite nuevamente por favor", "nuevo servicio", "oportunidad unica", "me confirma su",
            "enviaremos", "le enviaremos", "le estaremos"
        ]

        //Client key words
        const clientKeyWords = [
            "gracias", "no gracias", "me interesa", "no me interesa", "tengo una inquietud", "pero es que", "ahora no"
        ]

        //Warning words
        const warningWords = ["cedula", "telefono", "direccion"]

        //Conversation
        let conversation = [{"person": "", "frase": "" }]

        // On document load resolve the SDK dependecy
        function Initialize(onComplete) {
            require(["Speech.Browser.Sdk"], function (SDK) {
                onComplete(SDK);
            });
        }

        //Identify speaker
        function RecognizePerson(frase) {
            const agentWeight = agentKeyWords.filter((palabra)=>{
                    return frase.indexOf(palabra) !== -1
                })

            const clientWeight = clientKeyWords.filter((palabra)=>{
                    return frase.indexOf(palabra) !== -1
                })

            const speaker = agentWeight.length > clientWeight.length ? "Agent" : "Client"
            console.log("agentWeight.length", agentWeight.length, "clientWeight.length", clientWeight.length, "-> Speaker: ", speaker)
            return speaker
        }


        function encripData(message) {
            const encryptedAES = CryptoJS.AES.encrypt(message, "My Secret Passphrase");
            console.log("ENCRIPT", encryptedAES)
            const decryptedBytes = CryptoJS.AES.decrypt(encryptedAES, "My Secret Passphrase");
            console.log("DECRIPT",decryptedBytes)
            const plaintext = decryptedBytes.toString(CryptoJS.enc.Utf8);

            return encryptedAES
        }


        var cleanedSpeech = '';

        // On doument load resolve the SDK dependecy
        function Initialize(onComplete) {
            require(["Speech.Browser.Sdk"], function (SDK) {
                onComplete(SDK);
            });
        }

    
        // Setup the recongizer
        function RecognizerSetup(SDK, recognitionMode, language, format, subscriptionKey) {

            switch (recognitionMode) {
                case "Interactive":
                    recognitionMode = SDK.RecognitionMode.Interactive;
                    break;
                case "Conversation":
                    recognitionMode = SDK.RecognitionMode.Conversation;
                    break;
                case "Dictation":
                    recognitionMode = SDK.RecognitionMode.Dictation;
                    break;
                default:
                    recognitionMode = SDK.RecognitionMode.Interactive;
            }

            var recognizerConfig = new SDK.RecognizerConfig(
                new SDK.SpeechConfig(
                    new SDK.Context(
                        new SDK.OS(navigator.userAgent, "Browser", null),
                        new SDK.Device("SpeechSample", "SpeechSample", "1.0.00000"))),
                recognitionMode,
                language, // Supported laguages are specific to each recognition mode. Refer to docs.
                format); // SDK.SpeechResultFormat.Simple (Options - Simple/Detailed)

            // Alternatively use SDK.CognitiveTokenAuthentication(fetchCallback, fetchOnExpiryCallback) for token auth
            var authentication = new SDK.CognitiveSubscriptionKeyAuthentication(subscriptionKey);

            var files = document.getElementById('filePicker').files;
            if (!files.length) {
                return SDK.CreateRecognizer(recognizerConfig, authentication);
            } else {
                return SDK.CreateRecognizerWithFileAudioSource(recognizerConfig, authentication, files[0]);
            }
        }

        // Start the recognition
        function RecognizerStart(SDK, recognizer) {

            recognizer.Recognize((event) => {
                /*
                 Alternative syntax for typescript devs.
                 if (event instanceof SDK.RecognitionTriggeredEvent)
                */

                let person = ''
                let encripMessage = ''
                if(event.result) {
                    person = RecognizePerson(event.result.NBest[0].Lexical)
                    encripMessage = encripData(event.result.NBest[0].Lexical)
                }

                console.log(encripMessage)           

                setCleanedSpeech(event, person);

                switch (event.Name) {
                    case "RecognitionTriggeredEvent":
                        UpdateStatus("Initializing");
                        break;
                    case "ListeningStartedEvent":
                        UpdateStatus("Listening");
                        break;
                    case "RecognitionStartedEvent":
                        UpdateStatus("Listening_Recognizing");
                        console.log(event)
                        break;
                    case "SpeechStartDetectedEvent":
                        UpdateStatus("Listening_DetectedSpeech_Recognizing");
                        console.log(JSON.stringify(event.Result)); // check console for other information in result
                        break;
                    case "SpeechHypothesisEvent":
                        UpdateRecognizedHypothesis(event.Result.Text, false);
                        console.log(JSON.stringify(event.Result)); // check console for other information in result
                        console.log("RESULTS", event.result)
                        break;
                    case "SpeechFragmentEvent":
                        UpdateRecognizedHypothesis(event.Result.Text, true);
                        console.log(JSON.stringify(event.Result)); // check console for other information in result
                        break;
                    case "SpeechEndDetectedEvent":
                        OnSpeechEndDetected();
                        UpdateStatus("Processing_Adding_Final_Touches");
                        console.log(JSON.stringify(event.Result)); // check console for other information in result
                        break;
                    case "SpeechSimplePhraseEvent":
                        UpdateRecognizedPhrase(JSON.stringify(event.Result, null, 3));
                        break;
                    case "SpeechDetailedPhraseEvent":
                        UpdateRecognizedPhrase(JSON.stringify(event.Result, null, 3));
                        break;
                    case "RecognitionEndedEvent":
                        OnComplete();
                        UpdateStatus("Idle");
                        console.log(JSON.stringify(event)); // Debug information
                        break;
                    default:
                        console.log(JSON.stringify(event)); // Debug information
                }
            })
                .On(() => {
                    // The request succeeded. Nothing to do here.
                },
                (error) => {
                    console.error(error);
                });
        }

        // Stop the Recognition.
        function RecognizerStop(SDK, recognizer) {
            // recognizer.AudioSource.Detach(audioNodeId) can be also used here. (audioNodeId is part of ListeningStartedEvent)
            recognizer.AudioSource.TurnOff();
            var file = new File([html2text(cleanedSpeech)], "hello world.txt", {type: "text/plain;charset=utf-8"});
            saveAs(file);
        }

        // converts HTML to text using Javascript
        function html2text(html) {
            html = html.replace(/<br>/g, "\r\n");
            var tag = document.createElement('div');
            tag.innerHTML = html;

            return tag.innerText;
        }
    </script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/crypto-js/3.1.2/rollups/aes.js"></script>
    <!-- Browser Hooks -->
    <script>
        var startBtn, stopBtn, hypothesisDiv, cleanedSpeechDiv, phraseDiv, statusDiv;
        var key, languageOptions, formatOptions, recognitionMode, inputSource, filePicker;
        var SDK;
        var recognizer;
        var previousSubscriptionKey;
        var cleanedSpeech;

        document.addEventListener("DOMContentLoaded", function () {
            createBtn = document.getElementById("createBtn");
            startBtn = document.getElementById("startBtn");
            stopBtn = document.getElementById("stopBtn");
            phraseDiv = document.getElementById("phraseDiv");
            hypothesisDiv = document.getElementById("hypothesisDiv");
            statusDiv = document.getElementById("statusDiv");
            key = document.getElementById("key");
            languageOptions = document.getElementById("languageOptions");
            formatOptions = document.getElementById("formatOptions");
            inputSource = document.getElementById("inputSource");
            recognitionMode = document.getElementById("recognitionMode");
            filePicker = document.getElementById('filePicker');
            cleanedSpeechDiv = document.getElementById('cleanedSpeechDiv');

            languageOptions.addEventListener("change", Setup);
            formatOptions.addEventListener("change", Setup);
            recognitionMode.addEventListener("change", Setup);

            startBtn.addEventListener("click", function () {
                if (key.value == "" || key.value == "YOUR_BING_SPEECH_API_KEY") {
                    alert("Please enter your Bing Speech subscription key!");
                    return;
                }
                if (inputSource.value === "File") {
                    filePicker.click();
                } else {
                    if (!recognizer || previousSubscriptionKey != key.value) {
                        previousSubscriptionKey = key.value;
                        Setup();
                    }

                    hypothesisDiv.innerHTML = "";
                    phraseDiv.innerHTML = "";
                    RecognizerStart(SDK, recognizer);
                    startBtn.disabled = true;
                    stopBtn.disabled = false;
                }
            });

            key.addEventListener("focus", function () {
                if (key.value == "YOUR_BING_SPEECH_API_KEY") {
                    key.value = "";
                }
            });

            key.addEventListener("focusout", function () {
                if (key.value == "") {
                    key.value = "YOUR_BING_SPEECH_API_KEY";
                }
            });

            filePicker.addEventListener("change", function () {
                Setup();
                hypothesisDiv.innerHTML = "";
                phraseDiv.innerHTML = "";
                cleanedSpeechDiv.innerHTML = "";
                RecognizerStart(SDK, recognizer);
                startBtn.disabled = true;
                stopBtn.disabled = false;
                filePicker.value = "";
            });

            stopBtn.addEventListener("click", function () {
                RecognizerStop(SDK, recognizer);
                startBtn.disabled = false;
                stopBtn.disabled = true;
            });

            Initialize(function (speechSdk) {
                SDK = speechSdk;
                startBtn.disabled = false;
            });
        });

        function lookForInfo(){

        }

        function Setup() {
            recognizer = RecognizerSetup(SDK, recognitionMode.value, languageOptions.value, SDK.SpeechResultFormat[formatOptions.value], key.value);
        }

        function UpdateStatus(status) {
            statusDiv.innerHTML = status;
        }

        function UpdateRecognizedHypothesis(text, append) {
            if (append)
                hypothesisDiv.innerHTML += text + " ";
            else
                hypothesisDiv.innerHTML = text;

            var length = hypothesisDiv.innerHTML.length;
            if (length > 403) {
                hypothesisDiv.innerHTML = "..." + hypothesisDiv.innerHTML.substr(length - 400, length);
            }
        }


        function setCleanedSpeech(objEvent, person) {
            if(objEvent.result != undefined){
                var arrSpeech = objEvent.result.NBest;
                cleanedSpeech = cleanedSpeech + "<br><li><b>" + person + ":</b> " + arrSpeech[0].Display + "</li>";
                cleanedSpeechDiv.innerHTML = cleanedSpeech;
            }

        }

        function OnSpeechEndDetected() {
            stopBtn.disabled = true;
        }

        function UpdateRecognizedPhrase(json) {
            hypothesisDiv.innerHTML = "";
            phraseDiv.innerHTML += json + "\n";
            console.log("JSON", json)
        }

        function OnComplete() {
            startBtn.disabled = false;
            stopBtn.disabled = true;
        }
    </script>
</body>

</html>